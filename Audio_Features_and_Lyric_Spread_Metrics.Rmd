---
title: "Analysis of Audio and Lyric Variation Metrics"
author: "Julia Stelman"
date: "3/22/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, message=FALSE, warning=FALSE, include = F}
library(plyr)
# import some functions from a former chapter
source('TTR.R')
library(cluster)
library(factoextra)

# import data
AFsongDF <- read.csv("AFsongDF.csv", row.names=1)

# clean up some of the junk
df <- na.exclude(AFsongDF[,c(-5,-16:-12,-23)])
df$sid <- as.character(df$sid)

# the data has a lot of audio features, and songs in many different languages
dat = df %>% subset(lang %in% c(
  'en', 'es', 'id', 'sw', 'nl')) %>%   #we don't want all the languages, just 5
  dplyr::select(sid, danceability, energy, key, loudness, speechiness, 
                acousticness, valence, tempo, lang) %>%   #and we only need some features
  mutate(lang = as.character(lang)) %>%   #remove the factor levels of lang
  mutate(lang = factor(lang)) %>%   #so that they can be reset to have only 5 levels
  inner_join(lyrics_sum3ds %>%   #innerjoin with the table of from TTR.R, but modified
              mutate(sid = Text) %>%   #for example, rename the column "Text" to "sid"
              select(sid, Types, Tokens, TTR),   #and save only the lyric metrics data. 
            by = "sid")

############################################

# for consistency
set.seed(10)

## take an equal random sample from all five languages of interest
En_ids <- subset(x=dat,subset = lang == 'en')$sid
## n = 20 because there are exactly 22 songs in Dutch, the language of the 5 with the fewest songs
En_ids <- sample(En_ids,20)
eS_ids <- subset(x=dat,subset = lang == 'es')$sid
eS_ids <- sample(eS_ids,20)
Id_ids <- subset(x=dat,subset = lang == 'id')$sid
Id_ids <- sample(Id_ids,20)
Nl_ids <- subset(x=dat,subset = lang == 'nl')$sid
Nl_ids <- sample(Nl_ids,20)
sW_ids <- subset(x=dat,subset = lang == 'sw')$sid
sW_ids <- sample(sW_ids,20)

# replace a misclassified song
En_ids_all <- subset(x=dat,subset = lang == 'en')$sid
En_ids[which(En_ids == "720ZYTSr4vSqcFYq2CTJKN")] <-
  sample(En_ids_all[-which(En_ids_all %in% En_ids)],1)
rm(En_ids_all)
# replace another misclassified song
Id_ids_all <- subset(x=dat,subset = lang == 'id')$sid
Id_ids[which(Id_ids == "7mrxKs2fqNiKBE8zePEP2l")] <-
  sample(Id_ids_all[-which(Id_ids_all %in% Id_ids)],1)
rm(Id_ids_all)

# make a data frame from the songs selected
esinw_df <- subset(x = dat, select = names(dat),
                   subset = doc_id %in% c(
                     En_ids, eS_ids, Id_ids, Nl_ids, sW_ids))

# save separate data frames for each langauge
engl = esinw_df[esinw_df$lang == 'en',] 
span = esinw_df[esinw_df$lang == 'es',] 
indo = esinw_df[esinw_df$lang == 'id',] 
swah = esinw_df[esinw_df$lang == 'sw',] 
dutc = esinw_df[esinw_df$lang == 'nl',] 

# make a list of the dfs that we need to use
lan = list(engl, span, indo, swah, dutc)
# make a list of the language labels
lanames = list('engl', 'span', 'indo', 'swah', 'dutc')

# make new data frames, one for each measure: 
## danceability, energy, key, loudness, speechiness, acousticness, valence, tempo, and TTR
# we'll create them in a list called dat2 using lapply

# we don't need cols 1, 11 & 12 (sid, Types & Tokens)
esinw_df2 <- lapply(c(2:9,13), function(x){  
  cbind(
    # each has three columns: the measure's value, the language, and the measure's name
    esinw_df[,c(x,10)], measure = names(esinw_df[x])) %>%
    # and rename the measure's value column as "value" so we can rbind all of the dfs later
    rename(value = names(esinw_df[x]))
})

# now rbind them
esinw_df3 = esinw_df2[[1]]
for (i in c(2:9)){
  esinw_df3 <- rbind(esinw_df3,esinw_df2[[i]])
}

# and take out the trash
rm(esinw_df2)
```

# Introduction

This is kind of a spin-off of the investigation done in "A Brief Analysis of Lyric Metrics." We take the same 100-song sample used in that study. The question we examine here is how do the songs from widely spoken languages vary in comparison to songs from non-widely spoken languages? 

In this chapter, I'll look at the spreads of a few audio and lyric features from 100 songs in 5 different languages (20 songs written in each language). I want to know if languages spoken across a wider geographical area produce a wider range of patterns in audio features and song lyrics. In other words, do the songs written by, say, Spanish-speaking artists vary more than songs written by, say, Indonesian-speaking artists? less? 

The following two languages make up the *widely spoken* group:

* English (en)

* Spanish (es)

The following three languages make up the *not widely spoken* group:

* Indonesian (id)

* Dutch (nl)

* Swahili (sw)

The distinction between the first and second groups is decided by whether a language is an official national language on at least three continents. 

I've used the Spotify Web API and the natural language processing package $\verb|quanteda|$ to calculate the following audio/ lyric features for audio and first few lines of lyrics in each of the 100 sampled songs. (20 songs were randomly sampled from each of the 5 languages.)

* Danceability (number between 0 and 1)

* Energy (number between 0 and 1)

* Key (category represented as a number between 0 and 11)*

* Loudness (number between -25 and 0)

* Speechiness (number between 0 and 1)

* Acousticness (number between 0 and 1)

* Valence (number between 0 and 1)**

* Tempo (number between 50 and 250)

* Type/Token Ratio, or TTR --> (# distinct words / # total words) in the first few lines of lyrics

*Each of the 12 numbers corresponds to one of the 12 keys on the chromatic scale, (e.g.  C, C\#, D, ..., A, A\#, B).

**I'm not entirely sure how Spotify measures valence, but I have the understanding that is an overall measure of how "happy" a song decidedly is based on other features.

# EDA

### Density plots

The plots below show the density curves, with each color-coded by language. For every measure besides Key, the density curves show us something about center, shape, and spread of their distributions among the songs of each language. 

Because key is actually a categorical variable, and not a quantitative variable, I used a different type of density plot for Key. Each key on the chromatic scale is associated with a certain value, 0-11, featured on the x-axis. The darker the shading at a value of x, the more songs written in the key associated with that x-value turned up in the sample. The idea is not to look for similarities in the locations of dark and light shading, but rather to compare and contrast the distribution of pigmentation across whole strips. This helps us get a better look at spread, which is all we are interested in, as shape and center don't have the same kind of meaning when dealing with a categorical variable as with quantitative variables.

```{r, message=F,warning=F}
library(ggridges)

# GG Ridge Plot

# make a ggplot and facet it by language
f1 <- ggplot(esinw_df3, aes(x = value, y = lang, fill = lang)) + 
  facet_wrap(measure~. , ncol = 3, scales = 'free')
# add some density plots to it to it for teh numical metric
f2 <- f1 + geom_density_ridges_gradient(data = subset(esinw_df3,measure!='key'),
                               scale = 1.8, rel_min_height = 0.01)
# add some gradient for the key (categorical) metric
f3 <- f2 +   stat_density(data = subset(esinw_df3,measure=='key'), 
                          aes(alpha = stat(count)),
               geom = "raster", position = "identity", bw = 1/2)
f3
```

In the Key plot (top right), the pink strip seems to be the splotchiest-looking. This means that there appears to be less variation of song key among songs written in English than among songs written in other languages. 

It would seem that the distributions of many features of English (pink) and Spanish (olive) music have similar shapes (danceability, loudness, speechiness, acousticness, tempo, and TTR). For all of these but loudness, these distributions seem to have commonalities not just of shape, but also of center and spread (ignoring abnormal tail behavior). 

Swahili's distribution (purple) always tends to march to the beat of its own drum (terrible pun intended). Truthfully though, if you look at all nine of the plots, there doesn't seem to be one in which the purple curve (or strip) seems to mimic the distribution of another color. 

What's interesting about Indonesian music (teal) is that acousticness is basically its only bimodally distributed feature. All its other features are distributed pretty unimodally, which is unusual. Meanwhile, every other language's music has at least two features that are distributed bimodally. 

All in all, there doesn't seem to be a super clear unifying difference between the more widely-spoken and less widely-spoken languages.

### Box plots

The boxplots below show the five-number-summaries and outliers for all of the same data that was used in the density curves above. Key, the categorical feature, is portrayed in a violin plot instead of a boxplot so that it is easier to see the concentrations at individual values of key. 

```{r}
# boxplots
# make the setup
f1 <- ggplot(esinw_df3, aes(y = value, x = lang, fill = lang))+ 
  facet_wrap(measure~. , ncol = 3, scales = 'free')
# boxplots for the true numeric variables
f2 <- f1+geom_boxplot(data = subset(esinw_df3, measure!='key')) + 
  coord_flip()
# violin plot for key (the categorical variable in disguise)
f3 <- f2+geom_violin(adjust = 1/5, data = subset(esinw_df3,measure=='key')) +
  coord_flip()
f3
```

There are lots of outliers in speechiness, which, while prominent in the density curves, is even more prominent here, especially for Indonesian. 

There don't seem to be any consistent patterns. As far as what these plots portray, there is no clear relationship between song feature distribution characteristics and widespokenness. 

# Methods

We want to know whether or not there is a difference between extent of variation within the music of more widely spoken languages vs music of less widely spoken languages. We're going to approach exploring this in two ways. 

* Running a statistical hypothesis test

* Performing K-means clustering

### Rank Sum tests

Rank Sum tests are usually not used in the way I am using them here. The Wilcoxon Rank Sum test is designed to be run on a data set whose observations are all in the same units. In order to deal with this restriction, I have to take some intermediate steps. 

I'll first calculate the spread metric (standard deviation or IQR) for each of the nine features for each of the 5 languages (5 * 9 = 45 calculations). Second, within each of the nine features separately, I'll perform ranking on the spread metric. Third, I'll pool together those *ranks* (each will be a value 1-5) to form the set of "observations" on which the Wilcoxon Rank Sum Test will be performed. I'll be giving each one of the 45 "observations" a label specifying which of the two contributing "populations" (widely spoken/ not widely spoken) it pertains to. During the Rank Sum test, each one will get a new overall rank based on where it falls relative to the rest of the "observations". 

Those "observations" originating from data of English or Spanish music pertain to the **widely spoken** "population", and those "observations" originating from data of Indonesian, Dutch, or Swahili music pertain to the **not widely spoken** "population."

### Kmeans Clustering

Unlike the Wilcoxon Rank Sum test, Kmeans, a clustering method, is built to handle feature-rich data. However, it is not built for computing how much evidence exists in favor of the clustering formation hypothesized. It only determines which of all the possible clustering formations has the most evidence in favor of it. Therefore I will take some additional steps to interpret the results of Kmeans as I would the outcome of a statistical test.

There are ${5 \choose 0} + {5 \choose 1} + {5 \choose 2} = 1 + 5 + 10 = 16$ possible ways that Kmeans could split 5 languages into exactly two groups. 

Assuming equal chance of each outcome exists when there is no relationship between varied-ness in audio/ lyric features and how widely spoken a language is, each outcome has exactly a 0.0625 chance of occurring. In other words, under the null hypothesis of no relationship, 0.0625 is the probability that the clustering procedure groups the languages in the following way:

* English (en), Spanish (es)

* Indonesian (id), Dutch (nl), Swahili (sw)

I'll take alpha to be 0.1. This way, if the pattern outlined above results, our p-value of 0.0625 will be small enough to allow us to reject the null hypothesis of no relationship.

I won't go into more detail on that, but I hope this has been enough to convince anyone reading this that some level of statistical thinking has gone into designing the unusual method I'll use in this segment of my analysis. 

#### **The need-to-know is this:** 

$H_0$: There is *no relationship* between varied-ness in audio/ lyric features and how widely spoken a language is.

$H_a$: There is a *relationship* between varied-ness in audio/ lyric features and how widely spoken a language is.

A statistical test has two possible outcomes: either the null gets rejected, thus supporting some alternative suspicion, or it doesn't.

If the clustering procedure groups the languages in the following way:

* English (en), Spanish (es)

* Indonesian (id), Dutch (nl), Swahili (sw)

then we reject the null. 

If the clustering procedure groups the languages in any other way, then we fail to to reject the null.

# Results

### Rank Sum tests

We'll perform two Wilcoxon Rank Sum tests. To start, we will use standard deviation as a metric of spread. Following that, we will repeat the same process but with IQR as our spread metric.

For the more detail on how spread metrics of Key were calculated, see the Appendix.

#### Standard Deviation Rank Sum test

The first of the following tables contains the standard deviation of each feature for each individual language. The second table replaces the standard deviations with their ranks. 

```{r, message=FALSE, warning=FALSE}
# Rank sum test of standard deviations

# make the matrix of "data"
sds <- esinw_df %>% select(-sid, -Tokens, -Types, -key) %>%
  group_by(lang) %>% summarise_all(sd) %>% ungroup() 
```

```{r, message=FALSE, warning=FALSE}
# turn the 0-11 key variable into 12 bernoull variables with 20 observations each
dummies <- esinw_df[order(esinw_df$lang),] %>% select(key) 

# and its levels
dum.levels <- levels(factor(unlist(dummies)))
key <- lapply(dummies, 
              function(x) table(sequence(nrow(dummies)), factor(x, levels = dum.levels)))$key

# use a different method for key, as it's a not actually a numeric variable.
# for each language, make a binary vector for each of the 12 possible values, 
## with 1s in all places where key = key[i], and 0s elsewhere
## take the sd of each of those 5 vectors, and then take the mean of those 5 sds
key_sds <- sapply(0:4,function(c){
  stdevskeys = c()
  for (i in 1:12){
    stdevskeys = append(stdevskeys,
                        sd(key[(c*(20) + (1:20)),i]))}
  mean(stdevskeys)}) 

# store that in the key column of the standard devation data frame
sds$key <- key_sds
```

Step 1: Calculate the standard deviation for each of the nine features for each of the five individual languages.

```{r, message=FALSE, warning=FALSE}
# add a column for widespokenness to the "data" matrix of standard deviations
sds <- esinw_df %>% select(-sid, -Tokens, -Types) %>%
  group_by(lang) %>% summarise_all(sd) %>% ungroup() %>%
  mutate(is_widely_spoken = ifelse(lang %in% c('en','es'), T, F))

# show the standard deviations
knitr::kable(sds %>% 
               mutate(`widely spoken?` = ifelse(is_widely_spoken, "yes", "no")) %>%
               select(-is_widely_spoken), 
             format = "markdown", caption = "Table 1: Standard deviation of each feature by language")
```

Step 2: Rank the five languages, within each feature separately, by standard deviation. 

```{r, message=FALSE, warning=FALSE}
# take their ranks
sd_ranks = sds
for (i in c(2:10)){
  sd_ranks[,i] <- sapply(sds[,i],identity) %>% rank
}

# show the ranks
knitr::kable(sd_ranks%>% 
               mutate(`widely spoken?` = ifelse(is_widely_spoken, "yes", "no")) %>%
               select(-is_widely_spoken), 
             format = "markdown", 
             caption = "Table 2: in-column ranks of standard deviations in Table 1")
```

```{r, message=F, warning=FALSE}
#Let's run a statistical test to evaluate the variances associated with each langauge. 

# we need to make a dataframe that has two colums, a value column and a label column
# the value column will actualy be a rank column (remember, we are takeing ranks of ranks)
# the label column will contain 40 TRUEs (indicating songs written in widely spoken languages)
## and 60 FALSEs (indicating songs written in not widely spoken languages)
wilcox_df <-  sd_ranks[sd_ranks$is_widely_spoken,1:10] %>% stack() %>% .[,1] %>%
  cbind("widely_spoken") %>% 
  rbind(
    sd_ranks[!sd_ranks$is_widely_spoken,1:10] %>% stack() %>% .[,1] %>%
      cbind("not_widely_spoken")
  ) %>% data.frame() 
names(wilcox_df) <- c("rank_sd","cat")
wilcox_df <- wilcox_df %>% mutate(rank_sd = as.character(rank_sd)) %>%
  mutate(rank_sd  = as.numeric(rank_sd))
```

Step 3: Take the values from Table 2 to be the set of "observations" on which the Wilcoxon Rank Sum Test is to be performed. Determine each one's individual *overall* rank. Keep track of which "observations" belong to which "population."

```{r, message=FALSE, warning=FALSE}
# create a new table to show my work
wilcox_table = wilcox_df

# change the categorical values to make the table more readable and smaller
wilcox_table$widely <- wilcox_table$cat %>% sapply(
  function(x) ifelse(x == "widely_spoken","`yes`",""))
# do this separately for the two language types
wilcox_table$` spoken?` <- wilcox_table$cat %>% sapply(
  function(x) ifelse(x == "not_widely_spoken","`no`",""))

# get rid of the old categorical variable column
wilcox_table$cat = NULL

# get the ranks like the wilcox test does, and save in obs.rank
obs.rank = wilcox_df$rank_sd %>% rank
# make these more readable by getting rid of ".0"s and put in "``"s for separation
wilcox_table$obs_rank = obs.rank %>% as.character() %>%
  sapply(function(x) paste0("`",x,"`"))

# make the values more readable by getting rid of ".0"s
wilcox_table$obs_value = wilcox_df$rank_sd 

# put it all together
wilcox_table <- wilcox_table %>% 
  select(obs_value, obs_rank, widely, ` spoken?`) %>%
  mutate(obs_value = as.character(obs_value))

# show the first half of the table
wilcox_table[order(wilcox_table$obs_rank)[1:26],] %>%
  t() %>% data.frame() %>% knitr::kable(col.names = NULL, align = "c")
```

##### $\verb||$

```{r, message=FALSE, warning=FALSE}
# show the second half of the table
wilcox_table[order(wilcox_table$obs_rank)[27:45],] %>%
  t() %>% data.frame() %>% knitr::kable(col.names = NULL, align = "c")

# delete the table
rm(wilcox_table)
```

##### $\verb||$ $\verb||$

Above are the values used as observations, their overall ranks, and whether or not they each belong to the widely spoken language group. They're ordered by overall rank. 

Now let's run the test to see if the variation behavior of songs' audio/ lyric features (as can be detected at the standard deviation level) is associated with how widely spoken the language of their lyrics:

Alternative Hypothesis: The features of music written in more widely spoken languages will vary to either a greater or a lesser extent than the features of music written in less widely spoken languages.

```{r, message=FALSE, warning=FALSE}
# now the test
wilcox.test(rank_sd ~ cat, data = wilcox_df, alternative = "two.sided")
```

As 0.513 is a very large p-value, it seems there is not evidence of a unidirectional relationship between varied-ness within audio/ lyric features and how widely spoken a language is. Or at least there is not evidence of such a relationship that is detectable on the standard deviation level. 

#### IQR Rank Sum test

The first of the following tables contains the IQR of each feature for each individual language. The second table replaces the IQRs with their ranks. 

```{r, message=FALSE, warning=FALSE}
# Rank sum test of iqrs
iqrs <- esinw_df %>% select(-sid, -Tokens, -Types) %>%
  group_by(lang) %>% summarise_all(IQR) %>% ungroup() %>%
  mutate(is_widely_spoken = ifelse(lang %in% c('en','es'), T, F))

# use a different method for key, as it's a not actually a numeric variable.
# for each language, make a binary vector for each of the 12 possible values, 
## with 1s in all places where key = key[i], and 0s elsewhere
## take the iqr of each of those 5 vectors, and then take the mean of those 5 iqrs
key_iqrs <- sapply(0:4,function(c){
  iqrkeys = c()
  for (i in 1:12){
    iqrkeys = append(iqrkeys,
                        IQR(key[(c*(20) + (1:20)),i]))
  }
  mean(iqrkeys)
  }) 

iqrs$key <- key_iqrs
```

Step 1: Calculate the IQR for each of the nine features for each of the five individual languages.

```{r, message=FALSE, warning=FALSE}
# show the standard deviations
knitr::kable(iqrs%>% 
               mutate(`widely spoken?` = ifelse(is_widely_spoken, "yes", "no")) %>%
               select(-is_widely_spoken), 
             format = "markdown", 
             caption = "Table 3: Inter-Quartile Range (IQR) of each feature by language")
```

Step 2: Rank the five languages, within each feature separately, by IQR. 

```{r, message=FALSE, warning=FALSE}
iqr_ranks = iqrs
for (i in c(2:10)){
  iqr_ranks[,i] <- sapply(iqrs[,i],identity) %>% rank
}

# show the ranks
knitr::kable(iqr_ranks%>% 
               mutate(`widely spoken?` = ifelse(is_widely_spoken, "yes", "no")) %>%
               select(-is_widely_spoken), 
             format = "markdown", 
             caption = "Table 4: in-column ranks of IQRs in Table 4")
```

Now let's run a Wilcoxon Rank Sum test on the Inter-quartile ranges:

```{r, message=F, warning=FALSE}
# we need to make a dataframe that has two colums, a value column and a label column
# the value column will actualy be a rank column (remember, we are taking ranks of ranks)
# the label column will contain 40 TRUEs (indicating songs written in widely spoken languages)
## and 60 FALSEs (indicating songs written in not widely spoken languages)
wilcox_df2 <-  iqr_ranks[iqr_ranks$is_widely_spoken,1:10] %>% 
  stack() %>% .[,1] %>%
  cbind("widely_spoken") %>% 
  rbind(
    iqr_ranks[!iqr_ranks$is_widely_spoken,1:10] %>% stack() %>% .[,1] %>%
      cbind("not_widely_spoken")
  ) %>% data.frame() 
names(wilcox_df2) <- c("rank_iqr","cat")
wilcox_df2 <- wilcox_df2 %>% mutate(rank_iqr = as.character(rank_iqr)) %>%
  mutate(rank_iqr = as.numeric(rank_iqr))
```

Step 3: Take the values from Table 2 to be the set of "observations" on which the Wilcoxon Rank Sum Test is to be performed. Determine each one's individual *overall* rank. Keep track of which "observations" belong to which "population."

```{r, message=FALSE, warning=FALSE}
# create a new table to show my work
wilcox_table = wilcox_df2

# change the categorical values to make the table more readable and smaller
wilcox_table$widely <- wilcox_table$cat %>% sapply(
  function(x) ifelse(x == "widely_spoken","`yes`",""))
# do this separately for the two language types
wilcox_table$` spoken?` <- wilcox_table$cat %>% sapply(
  function(x) ifelse(x == "not_widely_spoken","`no`",""))

# get rid of the old categorical variable column
wilcox_table$cat = NULL

# get the ranks like the wilcox test does, and save in obs.rank
obs.rank = wilcox_df2$rank_iqr %>% rank
# make these more readable by getting rid of ".0"s and put in "``"s for separation
wilcox_table$obs_rank = obs.rank %>% as.character() %>%
  sapply(function(x) paste0("`",x,"`"))

# make the values more readable by getting rid of ".0"s
wilcox_table$obs_value = wilcox_df2$rank_iqr 

# put it all together
wilcox_table <- wilcox_table %>% 
  select(obs_value, obs_rank, widely, ` spoken?`) %>%
  mutate(obs_value = as.character(obs_value))

# show the first half of the table
wilcox_table[order(obs.rank)[1:26],] %>%
  t() %>% data.frame() %>% knitr::kable(col.names = NULL, align = "c")
```

##### $\verb||$ $\verb||$ $\verb||$

```{r, message=FALSE, warning=FALSE}
#show the second half of the table
wilcox_table[order(obs.rank)[27:45],] %>%
  t() %>% data.frame() %>% knitr::kable(col.names = NULL, align = "c")

# delete the table
rm(wilcox_table)
```

##### $\verb||$ $\verb||$ $\verb||$ $\verb||$

Now let's run the test to see if the variation behavior of songs' audio/ lyric features (as can be detected at the IQR level) is associated with how widely spoken the language of their lyrics:

Alternative Hypothesis: The features of music written in more widely spoken languages will vary to either a greater or a lesser extent than the features of music written in less widely spoken languages.

```{r, message=FALSE, warning=FALSE}
# now the test
wilcox.test(rank_iqr ~ cat, data = wilcox_df2, alternative = "two.sided")
```

It's a smaller p-value than we got from standard deviation. Still, 0.1513 is too large of a p-value to provide evidence supporting the existence of a one-way spectrum of variablity in audio/ lyric features associated with how widely spoken a language is. 

Based on these results, there is *no relationship* between varied-ness in audio/ lyric features and wide-spokenness of lyric language. 

### Kmeans Clustering

```{r formatting, message=FALSE, warning=FALSE}
# make a function to format the table showing which is higher, which is lower. 
bold_max <- function(x) kableExtra::cell_spec(x, bold = (x == max(x)))
```

```{r}
# prep sd df for kmeans
sds <- sds %>% as.data.frame()
rownames(sds) <- sds$lang
sds <- sds %>% select(-lang, -is_widely_spoken)

# prep iqr df for kmeans
iqrs <- iqrs %>% as.data.frame()
rownames(iqrs) <- iqrs$lang
iqrs <- iqrs %>% select(-lang, -is_widely_spoken)
```

I used the $\verb|cluster|$ and $\verb|factoextra|$ packages to conduct Kmeans clustering analysis, first by Standard Deviation, and then by IQR. 

#### Kmeans Clustering by Standard Deviations
```{r}
# We want to see the data split into 2 clusters.
# So we specify "centers" to be 2.
km_sds <- kmeans(sds, centers = 2, nstart = 25)

# lets take a look at the important information about our clusters.
km_sds

# And plot the result wit with fviz_cluster
fviz_cluster(km_sds, data = sds)
```

The clusters actually split the languages into widely and not widely spoken languages! We reject the null and conclude that there is evidence of a relationship between varied-ness in audio/ lyric features and how widely spoken a language is at the standard deviation level!

Take a look at the numbers in Table 5 which is a reformated version of the table shown in the R output chunk above. The row containing cluster means for the cluster which was formed around English and Spanish is labeled "widely spoken." Seven times out of nine, the features of music from widely spoken languages varied *less*, on average, than features of music from "not widely spoken" languages, judged on the basis of standard deviation. 

```{r}
# make a table for the infomation that matters with useful labels
table5 <- km_sds$centers %>% round(3) %>% data.frame %>% mutate_all(bold_max)

# correct rownames
rownames(table5) <- c("widely spoken","not widely spoken")

# show table
table5 %>% knitr::kable(
  escape = F, booktabs = T,
  caption = "Table 5: Cluster means from Kmeans Clustering on Standard Deviation. Max of each column in bold.") %>%
  kableExtra::kable_styling() 
```

#### Kmeans Clustering by IQRs

Let's try it again with IQR instead of standard deviation.

```{r}
# once again, we'll start with 2 clusters
km_iqrs <- kmeans(iqrs, centers = 2, nstart = 25)

# information, please
km_iqrs

# Plotting the result...
fviz_cluster(km_iqrs, data = iqrs)
```

The algorithm did not split the data into the clusters we suspected. Therefore, we fail to reject the null and conclude that there is not evidence of relationship between varied-ness in audio/ lyric features and how widely spoken a language is at the IQR level.

# Discussion

Standard deviation is not outlier-resistant, which is one way IQR differs from it. Standard Deviation is also more inflated by bimodal distribution behavior than IQR is, and as we saw in those density curves, there were quite a few cases of bimodality. I found it interesting that the null was rejected in the standard deviation version of the Kmeans test but not in the IQR version. Yet, in the Rank Sum tests, though in neither version of the test was the null rejected, the standard deviation version resulted in a p-value that was, by far, the least rejectable (0.531).

I have a theory for why this would be. Because ranks were used instead of the original values in the Rank Sum tests, magnitude of difference was not able to have any influence. However, magnitude of difference *was* able to influence the Kmeans test. This difference between Rank Sum test and Kmeans test didn't seem to change much in the case of IQR. However, it made a huge difference in the case of standard deviation. Standard deviation has more moving parts than IQR, making it more likely that distances between two values in the set of 45 standard deviations would vary more than distances between two values in the set of 45 IQRs. This might be one reason why the conclusions of the two hypothesis tests for standard deviation differed. 

Now that there is finally a null rejection to talk about, let's discuss what could actually be causing it. As Table 5 made apparent, for 78% of features, there was less in-language variation in music from widely spoken languages than music from less widely spoken languages. 

This, I found quite interesting and unexpected. Initially, I predicited that, if anything, there would be *more* variation among songs from *more* widely spoken languages. The *more* places a language is spoken, the *more* speakers it has. The *more* speakers a language has, the *more* singers it has. The *more* singers that contribute their voices to music in a language, the *more* variation exists among music produced in it. 

However, there is another side to all of this. Even if the *list* of songs I began with for this study were truly a *simple random sample* of *all* the songs from each language, I'm still limited to only the songs with:

* audio feature data on Spotify,

* lyrics on Musixmatch,

* lyrics encoded in a way that the software I'm using can process,

* encoded lyrics decoded in a way that is recognized (as non-gibberish) by the machine translation API,

* and decoded lyrics correctly detected by Google Translate.

Probably, the more commercially successful the song, the more likely it is to have remained in the sampleable dataset by the end of all this. Therefore, we can't think just about the music that gets *made* by a lot of people. We have to think also about the music that gets *heard* by a lot of people. There are certain qualities associated with songs that get popular. One of them, undoubtedly, is a wide-spoken lyric language. 

I'm no expert, but I would guess that pop artists seeking to maximize their audiences don't opt to write their music in Swahili. On the other hand, those that *do* opt to write their music in Swahili probably aren't shooting for world-wide popularity above all else. Singers who write songs with pop music qualities have more incentive to write lyrics in more widely-spoken languages. Often, common goals result in common products. And if that common goal is commercial success, songs written in English or Spanish with pop music qualities are the common results. 

The music that remained in the dataset by the time I began sampling was probably a mix between pop music and non-pop music. However, it probably was not an unbiased mix. Music of the pop genre had probably been lost in the metadata collection process at a lower rate than music of other genres. This probably changed the genre diversity of the sampleable data across all five language groups, but had the highest pop-saturation effect on English and Spanish. 

# Acknowledgements

Thank you to Spotify, Musixmatch, Everynoise.com, and lang-detect for the help I got from your libraries, websites, and APIs in the data collection and cleaning phase of this project, which I did in Python. 

Also thank you to the R libraries $\verb|quanteda|$, $\verb|tidyverse|$, $\verb|DescTools|$, $\verb|caret|$, $\verb|dplyr|$, $\verb|stringi|$, $\verb|knitr|$, $\verb|ggplot2|$, $\verb|ggridges|$, $\verb|plyr|$, $\verb|cluster|$, $\verb|factoextra|$, and $\verb|kableExtra|$.


